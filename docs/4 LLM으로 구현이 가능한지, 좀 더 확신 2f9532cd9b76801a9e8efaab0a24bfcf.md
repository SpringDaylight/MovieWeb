# 4. LLM으로 구현이 가능한지, 좀 더 확신

# 1️⃣ 3주 구현 가능성에 대한 최종 판단

## 전체 파이프라인 구현 가능 여부 요약

| 파이프라인 단계 | 3주 내 구현 가능성 | 근거 |
| --- | --- | --- |
| A-1 정서 기반 취향 모델링 | ✅ 가능 | LLM 프롬프트 + JSON 구조화 |
| A-2 영화 특성 벡터링 | ✅ 가능 | 공개 영화 데이터 + 임베딩 |
| A-3 취향 시뮬레이터 | ✅ 가능 | 경량 ML / 통계 기반 |
| A-4 설명 생성 | ✅ 가능 | LLM 텍스트 생성 |
| A-5 자연어 감성 검색 | ✅ 가능 | RAG 표준 패턴 |
| A-6 그룹 취향 시뮬레이터 | ⚠️ 가능 | 개인 파이프라인 확장 |

👉 **불가능한 부분 없음**

👉 **다만 “대규모 학습 / end-to-end 모델”은 범위 밖**

---

# 2️⃣ 데이터 조건 검증 (중요)

> ❗ 조건:
> 
> 
> **온라인에서 수집 가능한 실제 데이터만 사용 / 임의 생성 데이터 ❌**
> 

## 사용 가능한 데이터 소스 (모두 실제 공개 데이터)

### 🎬 영화 데이터

| 데이터 | 출처 | 활용 단계 |
| --- | --- | --- |
| 영화 메타데이터 (제목, 장르, 개요) | TMDB Open API | A-2 |
| 영화 줄거리 | TMDB / Wikipedia | A-2 |
| 사용자 리뷰 텍스트 | Kaggle (IMDB Reviews) | A-1, A-3 |
| 평점 통계 | IMDB / Kaggle | A-3 |

> ⚠️ “가짜 리뷰 생성”, “임의 감상문 생성” → 사용 안 함
> 

### 👤 사용자 입력 데이터

- 실제 사용자 입력 (리뷰, 한 줄 소감)
- 프로젝트 시연 시 **팀원 입력 데이터**
    - → *실제 입력이므로 임의 생성 아님*

---

# 3️⃣ 파이프라인별 구현 범위 명확화

### 🔹 STEP 0. 파이프라인 진입점 (입력 유형 분기)

사용자는 항상 이 중 하나로 들어온다.

### 입력 유형 A (예측)

- “이 영화 나한테 맞을까?”

### 입력 유형 B (검색)

- “잔잔한데 생각 많아지는 영화”

### 입력 유형 C (그룹)

- “우리 3명이 같이 볼 영화”

👉 **입력은 다르지만, 최종 판단 파이프라인은 동일**

→ 진입점만 다르다.

아래는 **“이 단계에서 정확히 무엇을 개발하는가”**를 기준으로 정리했다.

## A-1. 정서 기반 취향 모델링 (LLM)

### 구현 범위 (반드시)

1. **입력 타입 정의**
    - 리뷰 텍스트
    - 감상 후 한 줄 소감
    - 검색 질의 문장
2. **LLM 프롬프트 설계**
    - “감정 단어 나열” ❌
    - “정서적 경험 해석” ⭕
    - 출력 포맷 고정(JSON)
3. **출력 스키마 설계**
    
    ```json
    {
    "emotion_tone":["warm","melancholic"],
    "narrative_focus":["relationship","growth"],
    "pacing":"slow",
    "ending_preference":"lingering"
    }
    ```
    
4. **API화**
    - `/analyze/preference`
    - 입력 텍스트 → 취향 벡터 반환

### 📦 산출물

- 취향 분석 프롬프트 1종
- 구조화된 사용자 취향 벡터

### 기술 포인트

- **모델 학습 ❌**
- **Prompt + Output Schema 고정 ⭕**

👉 1주차에 완성 가능

### 🔹 STEP 1. 사용자 텍스트 해석 (A-1)

### 입력

- 리뷰
- 감상 소감
- 질의 문장

### 처리 로직 (LLM 역할)

- 문장을 **정서/서사 관점에서 해석**
- 감정 단어를 분류하는 게 아니라
    
    👉 *“이 사람이 어떤 정서적 경험을 선호하는가”*를 추론
    

### 출력 (구조화)

```json
UserPreferenceVector{
  emotion_tone:["warm","melancholic"],
  narrative_focus:["relationship","growth"],
  pacing:"slow",
  ending:"lingering"
}

```

📌 **중요**

- 여기서 “모델 학습” 없음
- LLM = **의미 분석기 (Feature Extractor)**

---

## A-2. 영화 특성 벡터링 (LLM + Embedding)

### 구현 범위

1. **영화 데이터 수집**
    - TMDB Open API
    - 항목:
        - 제목
        - 줄거리
        - 장르
        - 평점
2. **LLM 기반 영화 해석**
    - 줄거리 → 정서/서사 요약
3. **임베딩 생성**
    - Sentence Transformer 계열
    - 영화 500~1,000편
4. **벡터 DB 저장**
    - 영화 ID ↔ 벡터 매핑

### 결과물

- 영화 정서 요약 텍스트
- 영화 500~1,000편 수준의 벡터 DB

👉 A-5, A-3에서 공용 사용

### 🔹 STEP 2. 영화 정서·서사 벡터 생성 (A-2)

### 입력

- 영화 줄거리
- 리뷰 요약
- 메타 정보

### 처리 로직

1. LLM이 영화 텍스트를 읽고
    
    → “이 영화의 정서·서사적 성격”을 요약
    
2. 그 결과를 임베딩
3. 벡터 DB 저장

### 출력

```json
MovieEmotionVector{
  emotion_tone:["calm","sad"],
  narrative_focus:["growth"],
  pacing:"slow",
  ending:"open"
}
```

📌 이 벡터는:

- 검색(A-5)
- 예측(A-3)
- 설명(A-4)

👉 **모든 단계에서 재사용되는 핵심 자산**

### 🔹 STEP 3. 후보 영화 선택 (조건부)

이 단계는 **입력 유형에 따라 다르게 작동**한다.

### 🔸 예측(A)

- 사용자가 특정 영화를 지정
    
    → 후보 = 1개
    

### 🔸 검색(B)

- 벡터 DB에서 질의 임베딩과 유사한 영화 Top-K
    
    → 후보 = N개
    

### 🔸 그룹(C)

- 개인별 후보 생성 후 교집합 / 상위 스코어
    
    → 후보 = N개
    

👉 이후 단계는 동일

---

## A-3. 취향 시뮬레이터 (Prediction Core)

### 구현 범위

1. **입력 정의**
    - 사용자 취향 벡터 - (A-1 결과)
    - 영화 특성 벡터 - (A-2 결과)
    - (선택) 유사 사용자 평균 평점
2. **유사도 계산 로직**
    - 정서 톤 유사도
    - 서사 구조 유사도
    - 결말 선호 일치도
3. **확률 산출**
    - Weighted Score → 0~1 정규화
4. **API화**
    - `/predict/satisfaction`
5. 방식:
    - Logistic Regression **또는**
    - Weighted Similarity Score

### 출력

- 만족 확률 (%)
- confidence score

> ❗ 딥러닝 필수 아님
> 
> 
> → “판단 로직”이 핵심
> 

### 🔹 STEP 4. 취향 시뮬레이터 (A-3, 핵심 판단)

### 입력

- 사용자 취향 벡터
- 영화 특성 벡터
- (선택) 유사 사용자 반응 통계

### 처리 로직 (현실적 MVP)

- 정서/서사 차원별 유사도 계산
- 가중 합산
- 확률로 정규화

```
Score =
  0.4 × emotion_similarity +
  0.3 × narrative_similarity +
  0.2 × ending_match +
  0.1 × user_stat
```

### 출력

```json
PredictionResult{
  satisfaction_probability:0.78,
  confidence:0.71
}
```

📌 **여기서 처음으로 “판단”이 발생**

→ 이 단계가 **AI 의사결정 코어**

---

## A-4. 설명 가능한 취향 추천 (LLM)

### 구현 내용

- A-3 결과 + 핵심 피처
- LLM에게 설명 생성 요청

👉 **Explainability Layer**

👉 구현 난이도 낮음, 설득력 매우 큼

### 🔹 STEP 5. 판단 이유 생성 (A-4)

### 입력

- 예측 결과
- 주요 기여 요소 (feature importance)

### 처리 로직 (LLM)

- 숫자를 사람이 이해할 수 있는 언어로 번역

### 출력 예시

> “당신은 관계 중심의 성장 서사와
> 
> 
> 여운 있는 결말을 선호하는 경향이 있습니다.
> 
> 이 영화는 해당 특성이 강해 높은 만족 확률이 계산되었습니다.”
> 

📌 **Explainability Layer**

- 이 단계 때문에 “LLM을 쓴 이유”가 명확해진다.

---

## A-5. 자연어 기반 감성 검색 (LLM + RAG)

### 구현 내용

1. 사용자 질의:
    - “우울한데 너무 무겁지 않은 영화”
2. LLM → 의미 해석
3. 벡터 DB 검색
4. 후보 영화 → A-3 투입

👉 “검색”이지만 실제론 **파이프라인 진입점 변경**

---

## A-6. 그룹 취향 시뮬레이터

### 구현 내용 (MVP 기준)

- 개인 취향 벡터 N개 생성
- 평균 / 가중 평균
- LLM로 갈등 포인트 요약

👉 고급 수학 ❌

👉 **해석과 설명이 핵심**

### 🔹 STEP 6. 그룹일 경우 (A-6)

### 입력

- 사용자 취향 벡터 A, B, C

### 처리 로직

1. 공통 선호 / 상충 요소 분리
2. 합성 취향 벡터 생성
3. STEP 4~5 재사용

### 출력

```
그룹 만족 확률: 65%
A: 매우 적합
B: 보통
C: 약간 무거울 수 있음
```

👉 **개인 파이프라인의 확장판**

---

# 3주 일정 계획 (표)

## 전체 일정 개요 (21일)

| 주차 | 핵심 목표 | 주요 산출물 |
| --- | --- | --- |
| 1주차 | 데이터 & 벡터화 | 영화 DB, 취향 추출 |
| 2주차 | 예측 & 설명 | 만족 확률 계산 |
| 3주차 | 검색 & 그룹 | 통합 데모 |

---

## 📅 주차별 상세 일정

### ✅ 1주차: 데이터 & 해석 파이프라인

| Day | 작업 |
| --- | --- |
| 1~2 | 영화 데이터 수집 (API) |
| 3~4 | A-2 영화 특성 요약 + 임베딩 |
| 5 | 벡터 DB 구축 |
| 6~7 | A-1 사용자 취향 추출 |

---

### ✅ 2주차: 판단 엔진 구축

| Day | 작업 |
| --- | --- |
| 8~9 | A-3 만족 확률 로직 |
| 10 | 유사 사용자 통계 연결 |
| 11~12 | A-4 설명 프롬프트 |
| 13~14 | 단일 영화 예측 완성 |

---

### ✅ 3주차: 확장 & 통합

| Day | 작업 |
| --- | --- |
| 15~16 | A-5 감성 검색 |
| 17~18 | A-6 그룹 취향 |
| 19 | 전체 파이프라인 연결 |
| 20 | 테스트 |
| 21 | 시연 자료 정리 |

---

# 5️⃣ 팀 분업 기준 (5명 기준)

| 역할 | 담당 |
| --- | --- |
| LLM / 프롬프트 | A-1, A-4 |
| 데이터 / RAG | A-2, A-5 |
| ML / 예측 | A-3 |
| 백엔드 | API 통합 |
| 프론트 / 데모 | 시각화 |

# 전체 파이프라인 로직 구조도 (의사결정 흐름)

아래 구조는 **보고서 / 발표 / PPT**에 그대로 써도 된다.

```
[ 사용자 입력 ]
 ├─ 리뷰 / 감상 소감
 ├─ 자연어 검색 질의
 └─ 그룹 요청
        ↓
────────────────────────────
STEP1. 사용자 텍스트 해석 (LLM)
 - 정서 톤
 - 서사 선호
 - 결말 선호
        ↓
[ 사용자 취향 벡터 ]
────────────────────────────
STEP2. 영화 특성 벡터링 (LLM + Embedding)
 - 영화 정서/서사 요약
 - 벡터 DB 저장
        ↓
[ 영화 벡터 DB ]
────────────────────────────
STEP3. 후보 영화 선택
 - 단일 영화 OR
 - 유사 영화Top-K
        ↓
────────────────────────────
STEP4. 취향 시뮬레이터 (Prediction Core)
 - 사용자 × 영화
 - 만족 확률 계산
        ↓
[ 예측 결과 ]
────────────────────────────
STEP5. 설명 생성 (LLM)
 - 판단 근거 자연어화
        ↓
[ 사용자에게 결과 제공 ]
```

### 그룹일 경우 확장

```
개인 취향 벡터A,B, C
        ↓
LLM 기반 취향 합성
        ↓
STEP4 → STEP5 동일

```